{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d56727",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import string\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "with open(\"pg100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read().lower()\n",
    "\n",
    "\n",
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "\n",
    "chars = sorted(set(text))\n",
    "char2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "\n",
    "class TextSequenceGenerator(Sequence):\n",
    "    def __init__(self, text, char2idx, seq_length, batch_size, vocab_size):\n",
    "        self.text = text\n",
    "        self.char2idx = char2idx\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.steps = (len(text) - seq_length - 1) // batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        start = idx * self.batch_size\n",
    "        for i in range(start, start + self.batch_size):\n",
    "            seq_in = self.text[i:i + self.seq_length]\n",
    "            seq_out = self.text[i + self.seq_length]\n",
    "            X_batch.append([self.char2idx[c] for c in seq_in])\n",
    "            y_batch.append(self.char2idx[seq_out])\n",
    "        return np.array(X_batch), to_categorical(y_batch, num_classes=self.vocab_size)\n",
    "\n",
    "\n",
    "\n",
    "sequence_length = 100\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=sequence_length))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "\n",
    "train_generator = TextSequenceGenerator(text, char2idx, sequence_length, batch_size, vocab_size)\n",
    "early_stop = EarlyStopping(monitor=\"loss\", patience=3)\n",
    "\n",
    "model.fit(train_generator, epochs=epochs, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "\n",
    "start_index = np.random.randint(0, len(text) - sequence_length - 1)\n",
    "seed_text = text[start_index:start_index + sequence_length]\n",
    "generated_text = seed_text\n",
    "\n",
    "for _ in range(500):\n",
    "    input_sequence = np.array([[char2idx[char] for char in seed_text]])\n",
    "    prediction = model.predict(input_sequence, verbose=0)[0]\n",
    "    next_index = np.argmax(prediction)\n",
    "    next_char = idx2char[next_index]\n",
    "\n",
    "    generated_text += next_char\n",
    "    seed_text = seed_text[1:] + next_char\n",
    "\n",
    "\n",
    "\n",
    "with open(\"generated_output.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(\"Seed Text:\\n\" + seed_text + \"\\n\\nGenerated Text:\\n\" + generated_text)\n",
    "\n",
    "print(\"✅ Text generation complete! Check 'generated_output.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24c97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "300/300 [==============================] - 38s 114ms/step - loss: 2.8831\n",
      "Epoch 2/5\n",
      "300/300 [==============================] - 37s 123ms/step - loss: 2.4523\n",
      "Epoch 3/5\n",
      "300/300 [==============================] - 38s 128ms/step - loss: 2.2975\n",
      "Epoch 4/5\n",
      "300/300 [==============================] - 36s 119ms/step - loss: 2.2142\n",
      "Epoch 5/5\n",
      "300/300 [==============================] - 39s 129ms/step - loss: 2.1635\n",
      "✅ Quick text generation complete! Check 'generated_output.txt'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import string\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "with open(\"pg100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read(200000).lower()  # Limit to first 200k characters for speed\n",
    "\n",
    "# Remove punctuation\n",
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "chars = sorted(set(text))\n",
    "char2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "class TextSequenceGenerator(Sequence):\n",
    "    def __init__(self, text, char2idx, seq_length, batch_size, vocab_size, step=5):\n",
    "        self.text = text\n",
    "        self.char2idx = char2idx\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.step = step\n",
    "        self.indices = list(range(0, len(text) - seq_length - 1, step))\n",
    "        self.steps = len(self.indices) // batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        start = idx * self.batch_size\n",
    "        for i in range(start, start + self.batch_size):\n",
    "            seq_start = self.indices[i]\n",
    "            seq_in = self.text[seq_start:seq_start + self.seq_length]\n",
    "            seq_out = self.text[seq_start + self.seq_length]\n",
    "            X_batch.append([self.char2idx[c] for c in seq_in])\n",
    "            y_batch.append(self.char2idx[seq_out])\n",
    "        return np.array(X_batch), to_categorical(y_batch, num_classes=self.vocab_size)\n",
    "\n",
    "\n",
    "\n",
    "seq_length = 100\n",
    "batch_size = 128\n",
    "epochs = 5  # Fewer epochs for speed\n",
    "step = 5 \n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=seq_length))\n",
    "model.add(LSTM(64))  # Reduced size LSTM\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "\n",
    "train_generator = TextSequenceGenerator(text, char2idx, seq_length, batch_size, vocab_size, step=step)\n",
    "early_stop = EarlyStopping(monitor=\"loss\", patience=2)\n",
    "\n",
    "model.fit(train_generator, epochs=epochs, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "\n",
    "start_index = np.random.randint(0, len(text) - seq_length - 1)\n",
    "seed_text = text[start_index:start_index + seq_length]\n",
    "generated_text = seed_text\n",
    "\n",
    "for _ in range(500):\n",
    "    input_sequence = np.array([[char2idx[char] for char in seed_text]])\n",
    "    pred = model.predict(input_sequence, verbose=0)[0]\n",
    "    next_index = np.argmax(pred)\n",
    "    next_char = idx2char[next_index]\n",
    "\n",
    "    generated_text += next_char\n",
    "    seed_text = seed_text[1:] + next_char\n",
    "\n",
    "\n",
    "\n",
    "with open(\"generated_output.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
    "    output_file.write(\"Seed Text:\\n\" + seed_text + \"\\n\\nGenerated Text:\\n\" + generated_text)\n",
    "\n",
    "print(\"✅ Quick text generation complete! Check 'generated_output.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc8a3e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "449/449 [==============================] - 83s 177ms/step - loss: 2.7614\n",
      "Epoch 2/10\n",
      "449/449 [==============================] - 66s 146ms/step - loss: 2.3427\n",
      "Epoch 3/10\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 2.2300\n",
      "Epoch 4/10\n",
      "449/449 [==============================] - 77s 171ms/step - loss: 2.1642\n",
      "Epoch 5/10\n",
      "449/449 [==============================] - 72s 161ms/step - loss: 2.1145\n",
      "Epoch 6/10\n",
      "449/449 [==============================] - 62s 137ms/step - loss: 2.0748\n",
      "Epoch 7/10\n",
      "449/449 [==============================] - 61s 135ms/step - loss: 2.0410\n",
      "Epoch 8/10\n",
      "449/449 [==============================] - 55s 123ms/step - loss: 2.0101\n",
      "Epoch 9/10\n",
      "449/449 [==============================] - 61s 137ms/step - loss: 1.9819\n",
      "Epoch 10/10\n",
      "449/449 [==============================] - 57s 127ms/step - loss: 1.9558\n",
      "✅ Quick text generation complete! Check 'generated_output.txt'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import string\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "\n",
    "with open(\"pg100.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read(300000).lower()  # Limit to first 200k characters for speed\n",
    "\n",
    "\n",
    "text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "\n",
    "chars = sorted(set(text))\n",
    "char2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2char = {idx: char for char, idx in char2idx.items()}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "\n",
    "\n",
    "class TextSequenceGenerator(Sequence):\n",
    "    def __init__(self, text, char2idx, seq_length, batch_size, vocab_size, step=5):\n",
    "        self.text = text\n",
    "        self.char2idx = char2idx\n",
    "        self.seq_length = seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.step = step\n",
    "        self.indices = list(range(0, len(text) - seq_length - 1, step))\n",
    "        self.steps = len(self.indices) // batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.steps\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        start = idx * self.batch_size\n",
    "        for i in range(start, start + self.batch_size):\n",
    "            seq_start = self.indices[i]\n",
    "            seq_in = self.text[seq_start:seq_start + self.seq_length]\n",
    "            seq_out = self.text[seq_start + self.seq_length]\n",
    "            X_batch.append([self.char2idx[c] for c in seq_in])\n",
    "            y_batch.append(self.char2idx[seq_out])\n",
    "        return np.array(X_batch), to_categorical(y_batch, num_classes=self.vocab_size)\n",
    "\n",
    "\n",
    "seq_length = 100\n",
    "batch_size = 128\n",
    "epochs = 10  # Fewer epochs for speed\n",
    "step = 5  \n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=seq_length))\n",
    "model.add(LSTM(64))  # Reduced size LSTM\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "\n",
    "\n",
    "train_generator = TextSequenceGenerator(text, char2idx, seq_length, batch_size, vocab_size, step=step)\n",
    "early_stop = EarlyStopping(monitor=\"loss\", patience=2)\n",
    "\n",
    "model.fit(train_generator, epochs=epochs, callbacks=[early_stop])\n",
    "\n",
    "\n",
    "\n",
    "start_index = np.random.randint(0, len(text) - seq_length - 1)\n",
    "seed_text = text[start_index:start_index + seq_length]\n",
    "generated_text = seed_text\n",
    "\n",
    "for _ in range(500):\n",
    "    input_sequence = np.array([[char2idx[char] for char in seed_text]])\n",
    "    prediction = model.predict(input_sequence, verbose=0)[0]\n",
    "    next_index = np.argmax(prediction)\n",
    "    next_char = idx2char[next_index]\n",
    "\n",
    "    generated_text += next_char\n",
    "    seed_text = seed_text[1:] + next_char\n",
    "\n",
    "\n",
    "\n",
    "with open(\"generated_output_new.txt\", \"w\", encoding=\"utf-8\") as out_file:\n",
    "    out_file.write(\"Seed Text:\\n\" + seed_text + \"\\n\\nGenerated Text:\\n\" + generated_text)\n",
    "\n",
    "print(\"✅ Quick text generation complete! Check 'generated_output.txt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207daa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
